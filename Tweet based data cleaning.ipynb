{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import emoji\n",
    "import emot\n",
    "import  re\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/warproxxx/.local/lib/python3.5/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../collection/data/tweet_rescrape.csv')\n",
    "bot_accounts = pd.read_csv('data/bot_id_username.csv')\n",
    "clean_accounts = pd.read_csv('data/non_bot_accounts.csv')\n",
    "\n",
    "bot_tweets = df[df['username'].isin(bot_accounts['username'])].reset_index(drop=True)\n",
    "\n",
    "clean_tweets = df[df['username'].isin(clean_accounts['username'])]\n",
    "\n",
    "bot_tweets['BotOrNot'] = 1\n",
    "clean_tweets['BotOrNot'] = 0\n",
    "\n",
    "combined_df = bot_tweets.append(clean_tweets, ignore_index=True)\n",
    "\n",
    "new_df = combined_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(tweet):    \n",
    "    for word in tweet.split(' '):\n",
    "        if (word.isalnum() and word == word.upper() and word.isdigit() == False and len(word) > 1):\n",
    "            tweet = tweet.replace(word, word + \" <allcaps>\")\n",
    "            \n",
    "            \n",
    "    tweet = emoji.demojize(tweet, delimiters=('<', '>'))\n",
    "\n",
    "    p.set_options(p.OPT.HASHTAG, p.OPT.MENTION, p.OPT.NUMBER, p.OPT.RESERVED,p.OPT.URL)\n",
    "    \n",
    "    tokenized = p.tokenize(tweet)\n",
    "    \n",
    "    res = emot.emoticons(tokenized)\n",
    "    \n",
    "    if 'mean' in res:\n",
    "        for i in range(len(res['mean'])):\n",
    "            tokenized = tokenized.replace(res['value'][i], \"<\" + res['mean'][i].split(' ')[0] + \">\")\n",
    "    \n",
    "    tokenized = tokenized.lower()\n",
    "    tokenized = tokenized.replace('><', '> <')\n",
    "    tokenized = tokenized.translate(str.maketrans('','',\"!\\\"“'&(”)*+,’-./:;=?[\\\\]^`{|}~\"))\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['tweettext'] = new_df['tweettext'].apply(lambda x: tokenize_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[['tweettext', 'retweets', 'username', 'timestamp', 'likes', 'replies', 'BotOrNot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['hashtag_count'] = new_df['tweettext'].apply(lambda x: x.count(\"<hashtag>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['mention_count'] = new_df['tweettext'].apply(lambda x: x.count(\"<mention>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['url_count'] = new_df['tweettext'].apply(lambda x: x.count(\"<url>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('data/new_labeled_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['hashtags'] = df['hashtags'].apply(lambda x: convert_to_list(x))\n",
    "# df['urls'] = df['urls'].apply(lambda x: convert_to_list(x))\n",
    "\n",
    "# df['hastag_count'] = df['hashtags'].apply(lambda x: len(x))\n",
    "# df['url_count'] = df['urls'].apply(lambda x: len(x))\n",
    "\n",
    "# df = df[['tweet_text', 'retweet_count', 'like_count', 'reply_count', 'hastag_count', 'url_count']]\n",
    "\n",
    "# df['mention_count'] = df['tweet_text'].str.count('@')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
